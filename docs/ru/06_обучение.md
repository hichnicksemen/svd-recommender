# Обучение Моделей

В этой главе мы подробно рассмотрим процесс обучения моделей рекомендательных систем: от подбора гиперпараметров до сохранения обученных моделей.

## Процесс обучения для разных типов моделей

### Closed-Form модели (EASE)

EASE имеет аналитическое решение - не требует итеративного обучения.

```python
from recommender import EASERecommender

model = EASERecommender(l2_reg=500.0)

# Обучение - просто вызовите fit()
model.fit(train.data)
# Занимает секунды, детерминированный результат
```

**Особенности:**
- ✅ Очень быстро
- ✅ Детерминированный результат (нет random seed)
- ✅ Не требует мониторинга сходимости
- ❌ Нельзя обучать инкрементально

### Итеративные модели (SLIM, ALS)

SLIM и ALS используют итеративную оптимизацию.

```python
from recommender import SLIMRecommender, ALSRecommender

# SLIM - ElasticNet для каждого item
slim = SLIMRecommender(
    l1_reg=0.1,
    l2_reg=0.1,
    max_iter=100,  # Итерации для ElasticNet
    tol=1e-4       # Tolerance для сходимости
)
slim.fit(train.data)

# ALS - чередующаяся оптимизация
als = ALSRecommender(
    n_factors=50,
    n_iterations=15,  # Чередующихся итераций
    reg=0.01,
    alpha=40.0
)
als.fit(train.data)
```

**Особенности:**
- ✅ Контролируемая сходимость (max_iter, tol)
- ✅ Можно остановить досрочно если сошлось
- ⚠️ Случайная инициализация влияет на результат (ALS)

### SGD модели (SVD++)

SVD++ использует стохастический градиентный спуск.

```python
from recommender import SVDPlusPlusRecommender

model = SVDPlusPlusRecommender(
    n_factors=20,
    n_epochs=20,      # Количество эпох
    lr=0.005,         # Learning rate - критичный параметр!
    reg=0.02          # Regularization
)

model.fit(train.data)
```

**Особенности:**
- ⚠️ Требует подбора learning rate
- ⚠️ Нужен мониторинг переобучения
- ✅ Можно обучать инкрементально (online learning)
- ⚠️ Случайная инициализация влияет на результат

### Deep Learning модели (NCF, LightGCN, SASRec)

Нейронные модели требуют PyTorch и GPU.

```python
from recommender import NCFRecommender

model = NCFRecommender(
    embedding_dim=64,
    hidden_layers=[128, 64, 32],
    dropout=0.2,
    learning_rate=0.001,  # Learning rate
    batch_size=256,       # Размер батча
    epochs=20,            # Количество эпох
    device='cuda'         # GPU!
)

model.fit(train.data)
```

**Особенности:**
- ⚠️ Много гиперпараметров
- ⚠️ Требует GPU для разумного времени обучения
- ⚠️ Обязателен мониторинг переобучения
- ⚠️ Случайность в инициализации, negative sampling, shuffle

## Подбор гиперпараметров

### Стратегии поиска

#### 1. Manual Tuning

Ручной подбор по опыту:

```python
# Начните с рекомендуемых значений
model = EASERecommender(l2_reg=500.0)
model.fit(train.data)

# Оцените на validation
results = evaluator.evaluate(model, val, task='ranking', train_data=train)
baseline_ndcg = results['ndcg@10']
print(f"Baseline NDCG@10: {baseline_ndcg:.4f}")

# Попробуйте соседние значения
for l2_reg in [200, 500, 800, 1000]:
    model = EASERecommender(l2_reg=l2_reg)
    model.fit(train.data)
    results = evaluator.evaluate(model, val, task='ranking', train_data=train)
    ndcg = results['ndcg@10']
    print(f"l2_reg={l2_reg}: NDCG@10={ndcg:.4f}")
```

**Когда использовать:**
- Малое количество гиперпараметров (1-2)
- Есть интуиция о разумных значениях
- Ограничен бюджет вычислений

#### 2. Grid Search

Перебор всех комбинаций:

```python
from itertools import product

# Определите сетку
param_grid = {
    'l1_reg': [0.01, 0.1, 0.5],
    'l2_reg': [0.01, 0.1, 0.5],
    'max_iter': [50, 100]
}

# Перебор
best_params = None
best_ndcg = 0

for l1, l2, max_iter in product(param_grid['l1_reg'], param_grid['l2_reg'], param_grid['max_iter']):
    print(f"Тестирование l1={l1}, l2={l2}, max_iter={max_iter}")
    
    model = SLIMRecommender(l1_reg=l1, l2_reg=l2, max_iter=max_iter)
    model.fit(train.data)
    
    results = evaluator.evaluate(model, val, task='ranking', train_data=train)
    ndcg = results['ndcg@10']
    
    print(f"  NDCG@10: {ndcg:.4f}")
    
    if ndcg > best_ndcg:
        best_ndcg = ndcg
        best_params = {'l1_reg': l1, 'l2_reg': l2, 'max_iter': max_iter}

print(f"\n✅ Лучшие параметры: {best_params}")
print(f"✅ NDCG@10: {best_ndcg:.4f}")
```

**Когда использовать:**
- 2-3 гиперпараметра
- Дискретные значения
- Нужна гарантия найти лучшую комбинацию

#### 3. Random Search

Случайное семплирование из диапазонов:

```python
import numpy as np

# Определите диапазоны
param_ranges = {
    'n_factors': (10, 100),
    'reg': (0.001, 0.1),
    'alpha': (10, 100)
}

# Random search
n_trials = 20
best_params = None
best_ndcg = 0

for trial in range(n_trials):
    # Случайные значения
    n_factors = np.random.randint(param_ranges['n_factors'][0], param_ranges['n_factors'][1])
    reg = np.random.uniform(param_ranges['reg'][0], param_ranges['reg'][1])
    alpha = np.random.uniform(param_ranges['alpha'][0], param_ranges['alpha'][1])
    
    print(f"Trial {trial+1}/{n_trials}: n_factors={n_factors}, reg={reg:.4f}, alpha={alpha:.1f}")
    
    model = ALSRecommender(n_factors=n_factors, n_iterations=15, reg=reg, alpha=alpha)
    model.fit(train.data)
    
    results = evaluator.evaluate(model, val, task='ranking', train_data=train)
    ndcg = results['ndcg@10']
    
    if ndcg > best_ndcg:
        best_ndcg = ndcg
        best_params = {'n_factors': n_factors, 'reg': reg, 'alpha': alpha}
        print(f"  ⭐ Новый лучший: NDCG@10={ndcg:.4f}")

print(f"\n✅ Лучшие параметры: {best_params}")
```

**Когда использовать:**
- Много гиперпараметров (4+)
- Непрерывные значения
- Ограничен бюджет (эффективнее grid search)

#### 4. Bayesian Optimization (Optuna)

Умный поиск с учётом предыдущих результатов:

```python
import optuna

def objective(trial):
    # Предложить гиперпараметры
    l2_reg = trial.suggest_float('l2_reg', 100, 1000, log=True)
    
    # Обучить модель
    model = EASERecommender(l2_reg=l2_reg)
    model.fit(train.data)
    
    # Оценить
    results = evaluator.evaluate(model, val, task='ranking', train_data=train)
    ndcg = results['ndcg@10']
    
    return ndcg

# Создать study
study = optuna.create_study(direction='maximize')

# Оптимизировать
study.optimize(objective, n_trials=50)

# Лучшие параметры
print(f"✅ Лучший NDCG@10: {study.best_value:.4f}")
print(f"✅ Лучшие параметры: {study.best_params}")

# История оптимизации
import matplotlib.pyplot as plt
from optuna.visualization import plot_optimization_history

fig = plot_optimization_history(study)
fig.show()
```

**Когда использовать:**
- Много гиперпараметров
- Дорогое обучение модели
- Хотите минимизировать количество trials

### Практические советы по подбору

#### 1. Разделите данные правильно

```python
# train/val/test split
from recommender import InteractionDataset

dataset = InteractionDataset(df, implicit=True, min_user_interactions=5)

# Вариант 1: train/val/test
train, val, test = dataset.split(
    test_size=0.2,
    val_size=0.1,
    strategy='random',
    seed=42
)

# Используйте:
# - train для обучения
# - val для подбора гиперпараметров
# - test для финальной оценки (только один раз!)
```

#### 2. Начните с диапазонов

Для каждого гиперпараметра:

```python
# EASE
l2_reg: [100, 200, 500, 800, 1000, 1500, 2000]

# SLIM
l1_reg: [0.01, 0.05, 0.1, 0.5, 1.0]
l2_reg: [0.01, 0.05, 0.1, 0.5, 1.0]

# ALS
n_factors: [20, 50, 100, 150, 200]
reg: [0.001, 0.01, 0.05, 0.1]
alpha: [1, 10, 20, 40, 60, 80, 100]

# SVD++
n_factors: [10, 20, 50, 100]
lr: [0.001, 0.005, 0.01, 0.05]
reg: [0.001, 0.01, 0.02, 0.05, 0.1]

# NCF
embedding_dim: [32, 64, 128, 256]
hidden_layers: [[64,32], [128,64,32], [256,128,64]]
lr: [0.0001, 0.0005, 0.001, 0.005]
dropout: [0.1, 0.2, 0.3, 0.5]
```

#### 3. Coarse-to-fine поиск

```python
# Шаг 1: Грубый поиск
for l2_reg in [100, 500, 1000, 2000]:
    # ... оценить

# Нашли оптимум около 500

# Шаг 2: Уточнение
for l2_reg in [300, 400, 500, 600, 700]:
    # ... оценить

# Нашли оптимум 600

# Шаг 3: Финальное уточнение
for l2_reg in [550, 600, 650]:
    # ... оценить
```

#### 4. Мониторьте несколько метрик

```python
# Не только NDCG!
evaluator = Evaluator(
    metrics=['precision', 'recall', 'ndcg', 'hit_rate'],
    k_values=[5, 10, 20]
)

results = evaluator.evaluate(model, val, task='ranking', train_data=train)

# Анализируйте trade-offs
print(f"Precision@10: {results['precision@10']:.4f}")
print(f"Recall@20: {results['recall@20']:.4f}")
print(f"NDCG@10: {results['ndcg@10']:.4f}")
```

## Early Stopping и Validation

Early stopping предотвращает переобучение, останавливая обучение когда validation метрика перестаёт улучшаться.

### Для SGD моделей (SVD++)

```python
class EarlyStopping:
    def __init__(self, patience=5, min_delta=0.0001):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False
    
    def __call__(self, val_score):
        if self.best_score is None:
            self.best_score = val_score
        elif val_score < self.best_score + self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = val_score
            self.counter = 0

# Использование (псевдокод - требует модификации модели)
early_stopping = EarlyStopping(patience=5)

for epoch in range(max_epochs):
    # Обучение
    model.train_epoch(train.data)
    
    # Validation
    val_results = evaluator.evaluate(model, val, task='rating_prediction')
    val_rmse = val_results['rmse']
    
    print(f"Epoch {epoch}: Val RMSE = {val_rmse:.4f}")
    
    # Проверка early stopping
    early_stopping(val_rmse)
    if early_stopping.early_stop:
        print(f"Early stopping at epoch {epoch}")
        break
```

### Для Deep Learning моделей

```python
# Для PyTorch моделей
import torch

class PyTorchEarlyStopping:
    def __init__(self, patience=10, min_delta=0, mode='max'):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.best_model_state = None
    
    def __call__(self, score, model):
        if self.best_score is None:
            self.best_score = score
            self.best_model_state = model.state_dict().copy()
            return False
        
        if self.mode == 'max':
            improved = score > self.best_score + self.min_delta
        else:
            improved = score < self.best_score - self.min_delta
        
        if improved:
            self.best_score = score
            self.best_model_state = model.state_dict().copy()
            self.counter = 0
            return False
        else:
            self.counter += 1
            if self.counter >= self.patience:
                # Восстановить лучшую модель
                model.load_state_dict(self.best_model_state)
                return True
            return False

# Использование для NCF
model = NCFRecommender(epochs=100, device='cuda')

# Обучение с early stopping (требует custom training loop)
early_stopping = PyTorchEarlyStopping(patience=10, mode='max')

# for epoch in range(model.epochs):
#     train_loss = model.train_epoch(train.data)
#     val_results = evaluator.evaluate(model, val, task='ranking', train_data=train)
#     val_ndcg = val_results['ndcg@10']
#     
#     if early_stopping(val_ndcg, model.model):
#         print(f"Early stopping at epoch {epoch}")
#         break
```

## Сохранение и загрузка моделей

### Базовое сохранение

Все модели поддерживают `save()` и `load()`:

```python
# Обучение модели
model = EASERecommender(l2_reg=500.0)
model.fit(train.data)

# Сохранение
model.save('models/ease_model.pkl')
print("✅ Модель сохранена")

# Загрузка
loaded_model = EASERecommender()
loaded_model.load('models/ease_model.pkl')
print("✅ Модель загружена")

# Проверка
recs = loaded_model.recommend([1, 2, 3], k=5)
print("✅ Модель работает")
```

### Что сохраняется?

```python
# Для EASE:
# - item_sim_matrix
# - user_mapping, item_mapping
# - seen_items
# - гиперпараметры (l2_reg)

# Для NCF (PyTorch):
# - model.state_dict() (веса нейросети)
# - user_mapping, item_mapping
# - гиперпараметры
```

### Версионирование моделей

```python
import datetime

# Сохранение с timestamp
timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
model_path = f'models/ease_l2reg500_{timestamp}.pkl'
model.save(model_path)

# Сохранение с метаданными
import json

metadata = {
    'model_type': 'EASERecommender',
    'hyperparameters': {'l2_reg': 500.0},
    'train_data': 'movielens-1m',
    'train_size': len(train.data),
    'val_ndcg@10': 0.385,
    'timestamp': timestamp
}

with open(f'models/ease_{timestamp}_metadata.json', 'w') as f:
    json.dump(metadata, f, indent=2)

print(f"✅ Модель и метаданные сохранены")
```

### Best Model Checkpointing

```python
class ModelCheckpoint:
    def __init__(self, filepath, monitor='ndcg@10', mode='max'):
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.best_score = None
    
    def __call__(self, model, metrics):
        score = metrics[self.monitor]
        
        if self.best_score is None:
            self.best_score = score
            model.save(self.filepath)
            print(f"✅ Сохранена начальная модель ({self.monitor}={score:.4f})")
        else:
            improved = (score > self.best_score if self.mode == 'max' 
                       else score < self.best_score)
            
            if improved:
                self.best_score = score
                model.save(self.filepath)
                print(f"✅ Сохранена улучшенная модель ({self.monitor}={score:.4f})")

# Использование
checkpoint = ModelCheckpoint('models/best_model.pkl', monitor='ndcg@10', mode='max')

# В цикле обучения
# for epoch in range(epochs):
#     model.train_epoch(train.data)
#     val_metrics = evaluator.evaluate(model, val, task='ranking', train_data=train)
#     checkpoint(model, val_metrics)
```

## Troubleshooting проблем обучения

### Проблема 1: Модель не сходится

**Симптомы:**
- Loss не уменьшается
- Метрики на validation очень низкие

**Решения:**

```python
# 1. Проверьте данные
print(f"Train size: {len(train.data)}")
print(f"Users: {train.data['user_id'].nunique()}")
print(f"Items: {train.data['item_id'].nunique()}")
print(f"Density: {len(train.data) / (train.data['user_id'].nunique() * train.data['item_id'].nunique()):.4f}")

# Слишком разреженные данные? Увеличьте min_user_interactions

# 2. Уменьшите learning rate (для SGD/DL моделей)
model = NCFRecommender(learning_rate=0.0001)  # Было 0.001

# 3. Увеличьте количество эпох
model = NCFRecommender(epochs=50)  # Было 20

# 4. Проверьте нормализацию (для explicit ratings)
from recommender.data import normalize_ratings
df = normalize_ratings(df, method='minmax')
```

### Проблема 2: Переобучение

**Симптомы:**
- Train метрики растут, val метрики падают
- Огромная разница между train и val

**Решения:**

```python
# 1. Увеличьте регуляризацию
model = ALSRecommender(reg=0.1)  # Было 0.01

# 2. Добавьте dropout (для DL)
model = NCFRecommender(dropout=0.5)  # Было 0.2

# 3. Уменьшите capacity
model = NCFRecommender(
    embedding_dim=32,  # Было 128
    hidden_layers=[64, 32]  # Было [256, 128, 64]
)

# 4. Early stopping
# См. раздел выше

# 5. Больше negative samples
model = NCFRecommender(n_negatives=10)  # Было 4
```

### Проблема 3: Медленное обучение

**Симптомы:**
- Обучение занимает часы
- Один epoch > 10 минут

**Решения:**

```python
# 1. Используйте GPU (для DL)
model = NCFRecommender(device='cuda')

# 2. Увеличьте batch size (для DL)
model = NCFRecommender(batch_size=2048)  # Было 256

# 3. Уменьшите количество итераций
model = ALSRecommender(n_iterations=10)  # Было 15
model = SLIMRecommender(max_iter=50)  # Было 100

# 4. Используйте более простую модель
# EASE вместо SLIM
# NCF вместо LightGCN

# 5. Сэмплируйте данные для экспериментов
train_sample = train.data.sample(frac=0.5, random_state=42)
```

### Проблема 4: Out of Memory (GPU)

**Симптомы:**
- CUDA out of memory error
- Process killed

**Решения:**

```python
# 1. Уменьшите batch size
model = NCFRecommender(batch_size=128)  # Было 1024

# 2. Уменьшите размерность
model = NCFRecommender(
    embedding_dim=32,  # Было 128
    hidden_layers=[64, 32]  # Было [256, 128, 64, 32]
)

# 3. Используйте gradient accumulation (требует модификации)
# accumulation_steps = 4
# effective_batch_size = batch_size * accumulation_steps

# 4. Переключитесь на CPU (медленнее, но работает)
model = NCFRecommender(device='cpu')

# 5. Очистите GPU cache
import torch
torch.cuda.empty_cache()
```

## Рекомендуемые workflow

### Workflow 1: Быстрое прототипирование

```python
# 1. Загрузка и базовый препроцессинг
df = load_movielens(size='100k')
dataset = InteractionDataset(df, implicit=True, min_user_interactions=5)
train, test = dataset.split(test_size=0.2, seed=42)

# 2. Быстрый baseline
model = EASERecommender(l2_reg=500.0)
model.fit(train.data)

# 3. Оценка
evaluator = Evaluator(metrics=['ndcg'], k_values=[10])
results = evaluator.evaluate(model, test, task='ranking', train_data=train)
print(f"NDCG@10: {results['ndcg@10']:.4f}")

# Готово! Заняло < 1 минуты
```

### Workflow 2: Полный эксперимент

```python
# 1. Данные: train/val/test
df = load_movielens(size='1m')
dataset = InteractionDataset(df, implicit=True, min_user_interactions=5)
train, val, test = dataset.split(test_size=0.2, val_size=0.1, seed=42)

# 2. Несколько моделей
models = {
    'EASE': EASERecommender(l2_reg=500.0),
    'ALS': ALSRecommender(n_factors=50, n_iterations=15),
    'NCF': NCFRecommender(embedding_dim=64, epochs=20, device='cuda')
}

# 3. Обучение и оценка
evaluator = Evaluator(metrics=['precision', 'recall', 'ndcg'], k_values=[10, 20])
results = {}

for name, model in models.items():
    print(f"\n{'='*60}")
    print(f"Обучение {name}...")
    print('='*60)
    
    model.fit(train.data)
    model_results = evaluator.evaluate(model, val, task='ranking', train_data=train)
    results[name] = model_results
    
    evaluator.print_results(model_results)
    
    # Сохранение
    model.save(f'models/{name.lower()}_model.pkl')

# 4. Выбор лучшей модели
best_model_name = max(results, key=lambda x: results[x]['ndcg@10'])
print(f"\n✅ Лучшая модель: {best_model_name}")

# 5. Финальная оценка на test (только один раз!)
best_model = models[best_model_name]
test_results = evaluator.evaluate(best_model, test, task='ranking', train_data=train)
print("\nФинальные результаты на test:")
evaluator.print_results(test_results)
```

### Workflow 3: Production pipeline

```python
# 1. Данные с полным препроцессингом
from recommender.data import filter_by_interaction_count, binarize_implicit_feedback

df = load_movielens(size='25m')
df = filter_by_interaction_count(df, min_user_interactions=10, min_item_interactions=10)
df = binarize_implicit_feedback(df, threshold=4.0)

# 2. Train/val/test split
dataset = InteractionDataset(df, implicit=True)
train, val, test = dataset.split(test_size=0.1, val_size=0.05, strategy='temporal', seed=42)

# 3. Подбор гиперпараметров на val
import optuna

def objective(trial):
    l2_reg = trial.suggest_float('l2_reg', 100, 2000, log=True)
    model = EASERecommender(l2_reg=l2_reg)
    model.fit(train.data)
    results = evaluator.evaluate(model, val, task='ranking', train_data=train)
    return results['ndcg@10']

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=30)

best_l2_reg = study.best_params['l2_reg']
print(f"✅ Лучший l2_reg: {best_l2_reg}")

# 4. Переобучение на train+val с лучшими параметрами
from pandas import concat
train_val = concat([train.data, val.data])

final_model = EASERecommender(l2_reg=best_l2_reg)
final_model.fit(train_val)

# 5. Финальная оценка на test
test_results = evaluator.evaluate(final_model, test, task='ranking', train_data=train)
print("\nФинальные результаты:")
evaluator.print_results(test_results)

# 6. Сохранение для production
final_model.save('production/ease_model_v1.pkl')

# 7. Метаданные
import json
metadata = {
    'model': 'EASE',
    'l2_reg': best_l2_reg,
    'train_size': len(train_val),
    'test_ndcg@10': test_results['ndcg@10'],
    'date': datetime.datetime.now().isoformat()
}
with open('production/model_metadata_v1.json', 'w') as f:
    json.dump(metadata, f, indent=2)

print("\n✅ Модель готова к production!")
```

## Что дальше?

- **[Инференс](07_инференс.md)** - генерация рекомендаций и оптимизация
- **[Оценка качества](08_оценка.md)** - детальный разбор метрик
- **[Продакшн решения](09_продакшн.md)** - deployment моделей

---

**Предыдущая глава**: [← Нейронные модели](05_модели_нейронные.md)  
**Следующая глава**: [Инференс →](07_инференс.md)


# –í–≤–µ–¥–µ–Ω–∏–µ

## –û–ø–∏—Å–∞–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏

**SOTA Recommender Systems Library** - —ç—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è, production-ready Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ 9 state-of-the-art –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤, –æ—Ç –ø—Ä–æ—Å—Ç—ã—Ö –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –¥–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

### –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

#### üéØ –®–∏—Ä–æ–∫–∏–π –≤—ã–±–æ—Ä –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤

–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –≤–∫–ª—é—á–∞–µ—Ç —Ç—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–æ–¥–µ–ª–µ–π:

**–ü—Ä–æ—Å—Ç—ã–µ –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ:**
- **EASE** - Embarrassingly Shallow Autoencoders (—Å—É–ø–µ—Ä –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å —Å –∑–∞–∫—Ä—ã—Ç—ã–º —Ä–µ—à–µ–Ω–∏–µ–º)
- **SLIM** - Sparse Linear Methods (–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–∞—è item-item –º–æ–¥–µ–ª—å)

**Matrix Factorization:**
- **SVD** - Singular Value Decomposition (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è)
- **SVD++** - SVD —Å —É—á–µ—Ç–æ–º implicit feedback
- **ALS** - Alternating Least Squares (–º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ)

**Deep Learning:**
- **NCF** - Neural Collaborative Filtering (GMF + MLP –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
- **LightGCN** - Graph Neural Networks (—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π SOTA)
- **SASRec** - Self-Attentive Sequential Recommendations (–¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)

#### üöÄ Production-ready —Ñ—É–Ω–∫—Ü–∏–∏

- **FAISS Integration** - —É—Å–∫–æ—Ä–µ–Ω–∏–µ inference –≤ 10-100 —Ä–∞–∑
- **REST API** - –≥–æ—Ç–æ–≤—ã–π FastAPI —Å–µ—Ä–≤–∏—Å –¥–ª—è deployment
- **Inference Optimization** - –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ, batching, ensemble
- **Comprehensive Evaluation** - 15+ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞
- **Flexible Data Processing** - –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥, negative sampling

#### üí° –ï–¥–∏–Ω—ã–π API

–í—Å–µ –º–æ–¥–µ–ª–∏ —Å–ª–µ–¥—É—é—Ç –µ–¥–∏–Ω–æ–º—É –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É:

```python
# –ï–¥–∏–Ω—ã–π API –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
model = ModelClass(**hyperparameters)
model.fit(train_data)
recommendations = model.recommend(user_ids, k=10)
predictions = model.predict(user_ids, item_ids)
model.save('model.pkl')
```

### –ö–æ–º—É –ø–æ–¥—Ö–æ–¥–∏—Ç —ç—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞?

- **–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è–º** - –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å SOTA –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏
- **Data Scientists** - –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º
- **ML Engineers** - –¥–ª—è production deployment —Å –≥–æ—Ç–æ–≤—ã–º–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
- **–°—Ç—É–¥–µ–Ω—Ç–∞–º** - –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞

### –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

**–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ:**
- Python 3.8+
- 4 GB RAM
- CPU

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–ª—è deep learning –º–æ–¥–µ–ª–µ–π:**
- Python 3.8+
- 16 GB RAM
- NVIDIA GPU —Å CUDA 11.0+
- 50+ GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ (–¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤)

### –ë–∞–∑–æ–≤–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

–î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–∞–∑–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ (EASE, SLIM, SVD, SVD++, ALS):

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/hichnicksemen/svd-recommender.git
cd svd-recommender

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∞–∑–æ–≤—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install numpy pandas scipy scikit-learn

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
pip install -e .
```

–ë–∞–∑–æ–≤–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–∫–ª—é—á–∞–µ—Ç:
- NumPy, Pandas –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏
- SciPy –¥–ª—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü
- Scikit-learn –¥–ª—è –º–µ—Ç—Ä–∏–∫ –∏ —É—Ç–∏–ª–∏—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å PyTorch (–¥–ª—è deep learning –º–æ–¥–µ–ª–µ–π)

–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è NCF, LightGCN, SASRec –Ω–µ–æ–±—Ö–æ–¥–∏–º PyTorch:

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –≤–∫–ª—é—á–∞—è PyTorch
pip install -r requirements.txt

# –ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch –æ—Ç–¥–µ–ª—å–Ω–æ (CPU)
pip install torch torchvision torchaudio

# –î–ª—è GPU (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

#### FAISS (–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞)

FAISS —É—Å–∫–æ—Ä—è–µ—Ç inference –≤ 10-100 —Ä–∞–∑ –¥–ª—è –±–æ–ª—å—à–∏—Ö –∫–∞—Ç–∞–ª–æ–≥–æ–≤:

```bash
# CPU –≤–µ—Ä—Å–∏—è
pip install faiss-cpu

# GPU –≤–µ—Ä—Å–∏—è (—Ç—Ä–µ–±—É–µ—Ç—Å—è CUDA)
pip install faiss-gpu
```

#### FastAPI (–¥–ª—è model serving)

–î–ª—è –∑–∞–ø—É—Å–∫–∞ REST API —Å–µ—Ä–≤–∏—Å–∞:

```bash
pip install fastapi uvicorn[standard]
```

#### Optuna (–¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)

–î–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:

```bash
pip install optuna
```

### –ü–æ–ª–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:

```bash
pip install -r requirements.txt
pip install faiss-gpu fastapi uvicorn optuna
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ:

```python
import recommender

print(f"–í–µ—Ä—Å–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {recommender.__version__}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
from recommender import (
    EASERecommender,
    SLIMRecommender,
    SVDRecommender,
    ALSRecommender
)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch –º–æ–¥–µ–ª–µ–π
try:
    from recommender import NCFRecommender, LightGCNRecommender, SASRecRecommender
    print("‚úÖ PyTorch –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã")
except ImportError:
    print("‚ö†Ô∏è  PyTorch –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch)")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ FAISS
try:
    import faiss
    print("‚úÖ FAISS –¥–æ—Å—Ç—É–ø–µ–Ω")
except ImportError:
    print("‚ö†Ô∏è  FAISS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")

print("\n‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
```

## –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

–î–∞–≤–∞–π—Ç–µ —Å–æ–∑–¥–∞–¥–∏–º –ø—Ä–æ—Å—Ç—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É –∑–∞ 5 –º–∏–Ω—É—Ç!

### –®–∞–≥ 1: –ò–º–ø–æ—Ä—Ç—ã

```python
from recommender import (
    EASERecommender,
    load_movielens,
    InteractionDataset,
    Evaluator
)
```

### –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö

```python
# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ MovieLens 100K
df = load_movielens(size='100k')

print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π")
print(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {df['user_id'].nunique()}")
print(f"Items: {df['item_id'].nunique()}")
```

### –®–∞–≥ 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

```python
# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è implicit feedback
dataset = InteractionDataset(
    df,
    implicit=True,  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ implicit (–±–∏–Ω–∞—Ä–Ω—ã–π)
    min_user_interactions=5  # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–¥–∫–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ test
train_data, test_data = dataset.split(
    test_size=0.2,
    strategy='random',
    seed=42
)

print(f"Train: {len(train_data)} –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π")
print(f"Test: {len(test_data)} –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π")
```

### –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

```python
# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ EASE –º–æ–¥–µ–ª–∏
model = EASERecommender(l2_reg=500.0)

print("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
model.fit(train_data.data)
print("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")
```

### –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π

```python
# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 5 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_ids = [1, 2, 3, 4, 5]
recommendations = model.recommend(
    user_ids,
    k=10,
    exclude_seen=True  # –ò—Å–∫–ª—é—á–∏—Ç—å —É–∂–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ items
)

# –í—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
for user_id, items in recommendations.items():
    item_ids = [item_id for item_id, score in items[:5]]
    print(f"User {user_id}: {item_ids}")
```

### –®–∞–≥ 6: –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞

```python
# –°–æ–∑–¥–∞–Ω–∏–µ evaluator
evaluator = Evaluator(
    metrics=['precision', 'recall', 'ndcg'],
    k_values=[5, 10, 20]
)

# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
results = evaluator.evaluate(
    model,
    test_data=test_data,
    task='ranking',
    exclude_train=True,
    train_data=train_data
)

# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
evaluator.print_results(results)
```

### –®–∞–≥ 7: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

```python
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
model.save('ease_model.pkl')

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
loaded_model = EASERecommender()
loaded_model.load('ease_model.pkl')
```

### –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä

–í–æ—Ç –ø–æ–ª–Ω—ã–π –∫–æ–¥ –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è:

```python
from recommender import (
    EASERecommender,
    load_movielens,
    InteractionDataset,
    Evaluator
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df = load_movielens(size='100k')

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
dataset = InteractionDataset(df, implicit=True, min_user_interactions=5)
train_data, test_data = dataset.split(test_size=0.2, strategy='random', seed=42)

# –û–±—É—á–µ–Ω–∏–µ
model = EASERecommender(l2_reg=500.0)
model.fit(train_data.data)

# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
recommendations = model.recommend([1, 2, 3], k=10, exclude_seen=True)
for user_id, items in recommendations.items():
    print(f"User {user_id}: {[item_id for item_id, _ in items[:5]]}")

# –û—Ü–µ–Ω–∫–∞
evaluator = Evaluator(metrics=['precision', 'recall', 'ndcg'], k_values=[10])
results = evaluator.evaluate(model, test_data, task='ranking', train_data=train_data)
evaluator.print_results(results)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
model.save('ease_model.pkl')
```

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–¥—É–ª–µ–π

–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–∞ –≤ –º–æ–¥—É–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É:

```
recommender/
‚îú‚îÄ‚îÄ core/                    # –ë–∞–∑–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ base.py             # BaseRecommender, ImplicitRecommender, ExplicitRecommender
‚îÇ   ‚îú‚îÄ‚îÄ data.py             # InteractionDataset
‚îÇ   ‚îî‚îÄ‚îÄ trainers.py         # PyTorchTrainer (–¥–ª—è deep learning)
‚îÇ
‚îú‚îÄ‚îÄ models/                  # –í—Å–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ simple/             # EASE, SLIM
‚îÇ   ‚îú‚îÄ‚îÄ factorization/      # SVD, SVD++, ALS
‚îÇ   ‚îú‚îÄ‚îÄ neural/             # NCF
‚îÇ   ‚îú‚îÄ‚îÄ graph/              # LightGCN
‚îÇ   ‚îî‚îÄ‚îÄ sequential/         # SASRec
‚îÇ
‚îú‚îÄ‚îÄ data/                    # –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
‚îÇ   ‚îú‚îÄ‚îÄ datasets.py         # –ó–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py    # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
‚îÇ   ‚îî‚îÄ‚îÄ samplers.py         # Negative sampling
‚îÇ
‚îú‚îÄ‚îÄ evaluation/             # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py          # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
‚îÇ   ‚îî‚îÄ‚îÄ evaluator.py        # Evaluator –∫–ª–∞—Å—Å
‚îÇ
‚îú‚îÄ‚îÄ utils/                  # Production —É—Ç–∏–ª–∏—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ inference.py        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è inference
‚îÇ   ‚îî‚îÄ‚îÄ faiss_index.py      # FAISS –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
‚îÇ
‚îî‚îÄ‚îÄ serving/                # Model serving
    ‚îî‚îÄ‚îÄ api.py              # FastAPI —Å–µ—Ä–≤–∏—Å
```

### –ë–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã

#### BaseRecommender

–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π:

```python
class BaseRecommender:
    def fit(self, interactions):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π"""
        raise NotImplementedError
    
    def predict(self, user_ids, item_ids):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ scores –¥–ª—è –ø–∞—Ä user-item"""
        raise NotImplementedError
    
    def recommend(self, user_ids, k=10, exclude_seen=False):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è top-K —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        raise NotImplementedError
    
    def save(self, path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        pass
    
    def load(self, path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        pass
```

#### ImplicitRecommender

–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ–ª–µ–π implicit feedback (EASE, SLIM, ALS):

```python
class ImplicitRecommender(BaseRecommender):
    """
    –ú–æ–¥–µ–ª–∏ –¥–ª—è implicit feedback (–±–∏–Ω–∞—Ä–Ω—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π)
    –ü—Ä–∏–º–µ—Ä—ã: –∫–ª–∏–∫–∏, –ø—Ä–æ—Å–º–æ—Ç—Ä—ã, –ø–æ–∫—É–ø–∫–∏
    """
```

#### ExplicitRecommender

–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ–ª–µ–π explicit feedback (SVD, SVD++):

```python
class ExplicitRecommender(BaseRecommender):
    """
    –ú–æ–¥–µ–ª–∏ –¥–ª—è explicit feedback (—Ä–µ–π—Ç–∏–Ω–≥–æ–≤)
    –ü—Ä–∏–º–µ—Ä—ã: –æ—Ü–µ–Ω–∫–∏ 1-5 –∑–≤—ë–∑–¥
    """
```

### InteractionDataset

–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π:

```python
class InteractionDataset:
    def __init__(self, df, implicit=True, min_user_interactions=0):
        """
        Args:
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ user_id, item_id, [rating], [timestamp]
            implicit: –ë–∏–Ω–∞—Ä–∏–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è implicit feedback
            min_user_interactions: –ú–∏–Ω–∏–º—É–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
    
    def split(self, test_size=0.2, val_size=0.0, strategy='random'):
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test"""
    
    def to_csr_matrix(self):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—É—é CSR –º–∞—Ç—Ä–∏—Ü—É"""
    
    def get_user_items(self, user_id):
        """–ü–æ–ª—É—á–∏—Ç—å items –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
```

### Pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏

–¢–∏–ø–∏—á–Ω—ã–π pipeline —Ä–∞–±–æ—Ç—ã —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π:

```
1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
   ‚Üì
2. –°–æ–∑–¥–∞–Ω–∏–µ InteractionDataset
   ‚Üì
3. –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ (—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)
   ‚Üì
4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
   ‚Üì
5. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
   ‚Üì
6. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
   ‚Üì
7. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
   ‚Üì
8. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
   ‚Üì
9. Production deployment (FAISS, API)
```

### –†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å

–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ª–µ–≥–∫–æ —Ä–∞—Å—à–∏—Ä—è–µ—Ç—Å—è. –î–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–≤–æ–µ–π –º–æ–¥–µ–ª–∏:

```python
from recommender.core import BaseRecommender

class MyRecommender(BaseRecommender):
    def __init__(self, my_param=1.0):
        super().__init__()
        self.my_param = my_param
    
    def fit(self, interactions):
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        pass
    
    def predict(self, user_ids, item_ids):
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        pass
    
    def recommend(self, user_ids, k=10, exclude_seen=False):
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        pass
```

## –ß—Ç–æ –¥–∞–ª—å—à–µ?

–ü–æ—Å–ª–µ –ø—Ä–æ—á—Ç–µ–Ω–∏—è —ç—Ç–æ–≥–æ –≤–≤–µ–¥–µ–Ω–∏—è, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º:

1. **[–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö](02_–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞_–¥–∞–Ω–Ω—ã—Ö.md)** - —É–∑–Ω–∞–π—Ç–µ –ø—Ä–æ –∑–∞–≥—Ä—É–∑–∫—É –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö
2. **[–ü—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏](03_–º–æ–¥–µ–ª–∏_–ø—Ä–æ—Å—Ç—ã–µ.md)** - –Ω–∞—á–Ω–∏—Ç–µ —Å EASE –∏ SLIM
3. **[–ü—Ä–∏–º–µ—Ä—ã](10_–ø—Ä–∏–º–µ—Ä—ã.md)** - –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–ª–Ω—ã–µ end-to-end –ø—Ä–∏–º–µ—Ä—ã

### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [GitHub Repository](https://github.com/hichnicksemen/svd-recommender)
- [Examples Directory](../../examples/)
- [Tests](../../tests/)
- [English Documentation](../../README.md)

---

**–°–ª–µ–¥—É—é—â–∞—è –≥–ª–∞–≤–∞**: [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ‚Üí](02_–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞_–¥–∞–Ω–Ω—ã—Ö.md)

